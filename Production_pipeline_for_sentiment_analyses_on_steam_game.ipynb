{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c719d493",
   "metadata": {},
   "source": [
    "### Sentiment analyses, review-based playtime estimations, and playtime-based recommendations\n",
    "\n",
    "In this notebook, we set up a pipeline that helps our user analyzing reviews of the game receiving a query. For this game, labelled as `A`, polarizied words in its reviews are extracted. The importance of these words are weighted by our user. The weightings are then used to make an estimation on our user's playtime on `A` using either `Random Forest` or `Document similarity` through word embeddings.\n",
    "\n",
    "After analyzing `A`, games sharing similar tags with `A` are explored through web-scrapping contents on Steam. Weightings prerviously input by our user are mapped to reviews of these games. For each of these games, a playtime estimation is made. Games with a long estimated playtime are recommennded to our user.\n",
    "\n",
    "Below, I perform a test run on this pipeline for the game, Port Royale 4 (ID: 1024650). Test runs on more recently released games on Steam have also been performed during code development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0dd218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import steamreviews\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from io import StringIO\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "import nltk\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c09290",
   "metadata": {},
   "source": [
    "#### 1.1 Codes for downloading reviews & extracting featurers of a game based on its steam id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b86c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class steam_game(object):\n",
    "    \n",
    "    def __init__(self, gameID, model='en_core_web_sm'):\n",
    "        self.gameID = gameID\n",
    "        nlp = spacy.load(model)\n",
    "        def tokenize_lemma(text):\n",
    "            return [w.lemma_ for w in nlp(text)]\n",
    "        self.tokenizer = tokenize_lemma\n",
    "        \n",
    "        stop_words = STOP_WORDS.union({'ll', 've', 'pron'})\n",
    "        stop_words_lemma = \\\n",
    "        set(w.lemma_ for w in nlp(' '.join(stop_words)))\n",
    "        self.stop_words = stop_words_lemma\n",
    "        self.nlp = nlp\n",
    "        \n",
    "\n",
    "    def get_reviews(self, language='english', min_num_reviews=5):\n",
    "        gameID = self.gameID\n",
    "        steamreviews.download_reviews_for_app_id_batch([gameID])\n",
    "        json_path = 'data/review_' + str(gameID) +'.json'\n",
    "        json_abspath = os.path.abspath(json_path)\n",
    "        with open(json_abspath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        f.close()\n",
    "        if data['reviews']:\n",
    "            data_dict = defaultdict(list)\n",
    "            for post_id, reviews in data['reviews'].items():\n",
    "                data_dict['post_id'] += [post_id]\n",
    "                data_dict['language'] += [reviews['language']]\n",
    "                data_dict['review_text'] += [reviews['review']]\n",
    "                data_dict['recommended'] += [reviews['voted_up']]\n",
    "                data_dict['play_time'] += [reviews['author']['playtime_forever']]\n",
    "                data_dict['purchase'] += [reviews['steam_purchase']]\n",
    "                data_dict['steam_id'] += [reviews['author']['steamid']]\n",
    "                data_dict['num_games_owned'] += [reviews['author']['num_games_owned']]\n",
    "                data_dict['num_reviews'] += [reviews['author']['num_reviews']]\n",
    "                data_dict['play_time_last_2_weeks'] += [reviews['author']['playtime_last_two_weeks']]\n",
    "\n",
    "            df = pd.DataFrame.from_dict(data_dict)\n",
    "            if language is not None:\n",
    "                df = df[df['language'] == language]\n",
    "        else:\n",
    "            print('Game/DILL {} has no review yet. An empty data set will be returned.'.format(gameID))\n",
    "            data_dict = {}\n",
    "            data_dict['post_id'] = []\n",
    "            data_dict['language'] = []\n",
    "            data_dict['review_text'] = []\n",
    "            data_dict['recommended'] = []\n",
    "            data_dict['play_time'] = []\n",
    "            data_dict['purchase'] = []\n",
    "            data_dict['steam_id'] = []\n",
    "            data_dict['num_games_owned'] = []\n",
    "            data_dict['num_reviews'] = []\n",
    "            data_dict['play_time_last_2_weeks'] = []\n",
    "            df = pd.DataFrame.from_dict(data_dict)\n",
    "        \n",
    "        self.data = df\n",
    "        if len(df.index) > min_num_reviews:\n",
    "            self.ready_for_ML = True\n",
    "        else:\n",
    "            self.ready_for_ML = False\n",
    "            print(\"Game/DILL {} has less than {} reviews. No further ML-based analyses will be made.\"\\\n",
    "                 .format(gameID, min_num_reviews))\n",
    "        \n",
    "    \n",
    "    def get_words(self, num_words=10, search_range=100):\n",
    "        if self.ready_for_ML:\n",
    "            stop_words = self.stop_words\n",
    "            nlp = self.nlp\n",
    "            tokenizer = self.tokenizer\n",
    "            est = Pipeline([('vectorizer', TfidfVectorizer(\n",
    "                stop_words=stop_words, ngram_range=(1,2),\n",
    "                tokenizer=tokenizer\n",
    "            )), ('classifier', MultinomialNB())])\n",
    "            #The below para_grid is for later convenience.\n",
    "            param_grid = {\n",
    "                'vectorizer__max_df': [0.7],\n",
    "                'vectorizer__min_df': [1],\n",
    "                'vectorizer__max_features': [5000]\n",
    "            }\n",
    "            gs_est = GridSearchCV(\n",
    "                est, param_grid, n_jobs=-1\n",
    "            )\n",
    "            X_train = self.data['review_text']\n",
    "            y_train = self.data['recommended']\n",
    "            gs_est.fit(X_train, y_train)\n",
    "            vocab = \\\n",
    "            gs_est.best_estimator_.named_steps['vectorizer'].vocabulary_ \n",
    "            coeff_pos = \\\n",
    "            gs_est.best_estimator_.named_steps['classifier'].feature_log_prob_[1] \n",
    "            coeff_neg = \\\n",
    "            gs_est.best_estimator_.named_steps['classifier'].feature_log_prob_[0]\n",
    "\n",
    "            self.vocab = vocab\n",
    "            self.coeff_pos = coeff_pos\n",
    "            self.coeff_neg = coeff_neg\n",
    "            self.vectorizer_param = gs_est.best_params_\n",
    "            self.recommend_classifier = gs_est.best_estimator_\n",
    "\n",
    "            polarity = coeff_pos - coeff_neg\n",
    "            indices = np.argsort(polarity)\n",
    "            positive_words = []\n",
    "            temp_count = 0\n",
    "            for word in vocab:\n",
    "                if vocab[word] in indices[-search_range:]:\n",
    "                    if set(w.pos_ for w in nlp(word)) == {'NOUN'}:\n",
    "                        positive_words.append(word)\n",
    "                        temp_count += 1\n",
    "                if temp_count >= num_words:\n",
    "                    break\n",
    "            negative_words = []\n",
    "            temp_count = 0\n",
    "            for word in vocab:\n",
    "                if vocab[word] in indices[:search_range]:\n",
    "                    if set(w.pos_ for w in nlp(word)) == {'NOUN'}:\n",
    "                        negative_words.append(word)\n",
    "                        temp_count += 1\n",
    "                if temp_count >= num_words:\n",
    "                    break\n",
    "            self.word_pos = positive_words\n",
    "            self.word_neg = negative_words\n",
    "        else:\n",
    "            print('Game/DILL {} has no review for analyses.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3374be0",
   "metadata": {},
   "source": [
    "#### 1.2 Codes for building an artifical review with an estimated voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f53b26e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_weights(words):\n",
    "    weights = []\n",
    "    for word in words:\n",
    "        while True:\n",
    "            try:\n",
    "                inp = \\\n",
    "                input(\n",
    "                    \"Please weight the importance (0-5) of this property/feature: {} \"\\\n",
    "                    .format(word)\n",
    "                    )\n",
    "                weight = int(inp)\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"The weight should be an integer between 0 and 5.\")\n",
    "        weights.append(weight)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ef5ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class artificial_reviews(object):\n",
    "    def __init__(self, \n",
    "                 game, \n",
    "                 weight_pos=[0]*10,\n",
    "                 weight_neg=[0]*10,\n",
    "                 pre_set_review=None):\n",
    "        self.word_pos = game.word_pos\n",
    "        self.word_neg = game.word_neg\n",
    "        self.weight_pos = weight_pos\n",
    "        self.weight_neg = weight_neg\n",
    "        if pre_set_review is None:\n",
    "            ww_L = []\n",
    "            for weight, word in zip(weight_pos, self.word_pos):\n",
    "                ww_L.extend([word] * weight)\n",
    "            for weight, word in zip(weight_neg, self.word_neg):\n",
    "                ww_L.extend([word] * weight)           \n",
    "            self.art_review = ' '.join(ww_L)\n",
    "        else:\n",
    "            self.art_review = pre_set_review\n",
    "        self.recommend = \\\n",
    "        game.recommend_classifier.predict([self.art_review])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0440d9dd",
   "metadata": {},
   "source": [
    "#### 1.3 Codes for estimating play time using ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6cb6da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"An iterators for sentences in a review.\"\"\"\n",
    "class nltk_sentences(object):\n",
    "    def __init__(self, *arrays):\n",
    "        self.arrays = arrays\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for array in self.arrays:\n",
    "            for document in array:\n",
    "                for sent in nltk.sent_tokenize(document):\n",
    "                    yield nltk.word_tokenize(sent)\n",
    "\n",
    "                    \n",
    "class nltk_tokenizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        transformed_X = []\n",
    "        for document in X:\n",
    "            tokenized_doc = []\n",
    "            for sent in nltk.sent_tokenize(document):\n",
    "                tokenized_doc += nltk.word_tokenize(sent)\n",
    "            transformed_X.append(np.array(tokenized_doc))\n",
    "        return np.asarray(transformed_X, dtype=object)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "    \n",
    "    \n",
    "class mean_embedding_vector(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = word2vec.wv.vector_size\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = nltk_tokenizer().fit_transform(X)\n",
    "        \n",
    "        return np.array([\n",
    "            np.mean(\n",
    "                [self.word2vec.wv[w] for w in words \\\n",
    "                 if w in self.word2vec.wv]\\\n",
    "                or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "    \n",
    "    \n",
    "def get_similar_doc(mean_array,\n",
    "                        ref_doc_index,\n",
    "                        docs, labels, \n",
    "                        num_output=5):\n",
    "    mse = np.sum(\n",
    "        (mean_array - mean_array[ref_doc_index,:]) ** 2, axis=1\n",
    "    )\n",
    "    labels = labels.values\n",
    "    output_tuples = []\n",
    "    for ind, document in enumerate(docs):\n",
    "        if ind == 0:\n",
    "            output_tuples.append(\n",
    "                (document, 0, mse[ind])\n",
    "            )\n",
    "        elif ind > 0:    \n",
    "            output_tuples.append(\n",
    "                (document, labels[ind-1], mse[ind])\n",
    "            )\n",
    "    output_tuples.sort(key=lambda x: x[2])\n",
    "    if len(output_tuples) >= num_output:\n",
    "        return output_tuples[1:num_output+1]\n",
    "    else:\n",
    "        return output_tuples[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "053aabff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class estimator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, game):\n",
    "        self.gameID = game.gameID\n",
    "        self.data = game.data\n",
    "        self.ready_for_ML = game.ready_for_ML\n",
    "        if self.ready_for_ML:\n",
    "            self.stop_words = game.stop_words\n",
    "            self.tokenizer = game.tokenizer\n",
    "            self.vectorizer_param = game.vectorizer_param\n",
    "            self.nlp = game.nlp\n",
    "            self.label_1 = game.data['play_time']\n",
    "            self.label_2 = game.data['play_time_last_2_weeks']\n",
    "            self.data_for_ml = game.data.drop(\n",
    "                ['post_id', 'steam_id','play_time','play_time_last_2_weeks'], \n",
    "                axis=1)\n",
    "            self.data_for_ml['review_length'] = \\\n",
    "            self.data_for_ml['review_text'].apply(lambda x : len(x.strip().split()))\n",
    "        else:\n",
    "            print(\"Game/DILL {} has no review for making any prerdiction.\".format(game.gameID))\n",
    "\n",
    "        \n",
    "    def get_play_time(self, art_review, \n",
    "                      min_num_data=3000, verbose=True):\n",
    "        if self.ready_for_ML:\n",
    "            num_data = self.data.shape[0]\n",
    "            X_user_dict = \\\n",
    "            {\n",
    "                'review_text': [art_review.art_review],\n",
    "                'recommended': art_review.recommend,\n",
    "                'purchase': [True],\n",
    "                'num_games_owned': [self.data_for_ml['num_games_owned'].mean()],\n",
    "                'num_reviews': [self.data_for_ml['num_reviews'].mean()],\n",
    "                'review_length': [len(art_review.art_review.strip().split())]\n",
    "            }\n",
    "            X_user_df = pd.DataFrame.from_dict(X_user_dict)\n",
    "\n",
    "\n",
    "            if num_data < min_num_data:\n",
    "                \"\"\"Use word embedding & review similarity\"\"\"\n",
    "                reviews = [X_user_df['review_text'].values[0]]\n",
    "                for review in self.data_for_ml['review_text'].values:\n",
    "                    reviews.append(review)\n",
    "                X_in = pd.DataFrame.from_dict({'text': reviews})\n",
    "                w2vec = \\\n",
    "                Word2Vec(\n",
    "                    sentences=nltk_sentences(X_in['text'].values),\n",
    "                    vector_size=100, window=5, min_count=1, workers=4\n",
    "                )\n",
    "                embedded = \\\n",
    "                mean_embedding_vector(w2vec).fit_transform(X_in['text'])\n",
    "                similar_users_play_time = \\\n",
    "                np.array([\n",
    "                    x[1] for x in get_similar_doc(embedded, 0, X_in['text'], self.label_1)\n",
    "                ])\n",
    "                self.prediction = similar_users_play_time.mean()\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        'Your expected play time as from users similar to you is: {} hour.'\\\n",
    "                        .format(self.prediction)\n",
    "                    )\n",
    "\n",
    "            elif num_data >= min_num_data:\n",
    "                \"\"\"Use random forest\"\"\"\n",
    "                X = self.data_for_ml\n",
    "                y = self.label_1\n",
    "\n",
    "                ng_tfidf = TfidfVectorizer(\n",
    "                    stop_words=self.stop_words,\n",
    "                    ngram_range=(1,2),\n",
    "                    tokenizer=self.tokenizer\n",
    "                )\n",
    "                Ohe = OneHotEncoder(sparse=False)\n",
    "                Ssr = StandardScaler()\n",
    "\n",
    "                data_preprocess = ColumnTransformer(\n",
    "                    [\n",
    "                        ('Ohe', Ohe, ['recommended','purchase']),\n",
    "                        ('Ssr',Ssr ,['num_games_owned', 'num_reviews', 'review_length']),\n",
    "                        ('vectorizer', ng_tfidf, 'review_text')\n",
    "                    ],\n",
    "                    remainder='drop'\n",
    "                )\n",
    "\n",
    "                rf_est = RandomForestRegressor(n_jobs=3,random_state=42)\n",
    "\n",
    "                pipe = Pipeline(\n",
    "                    [\n",
    "                        ('preprocessor', data_preprocess),\n",
    "                        ('estimator', rf_est)\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                param_grid = {\n",
    "                    'preprocessor__vectorizer__max_df': np.linspace(0.7, 1, num=4),\n",
    "                    'preprocessor__vectorizer__max_df': [0,1],\n",
    "                    'preprocessor__vectorizer__max_features': np.linspace(5000, 8000, num=4, dtype=int),\n",
    "                    'estimator__n_estimator': np.linspace(500, 1500, num=11, dtype=int),\n",
    "                    'estimator__max_depth': np.linspace(5, 10, num=6, dtype=int),\n",
    "                    'estimator__ccp_alpha': np.linspace(0, 0.2, num=5, dtype=float)\n",
    "                }\n",
    "                search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "                search.fit(X, y)\n",
    "                self.ML_model = {\n",
    "                    'best_params': search.best_params_,\n",
    "                    'best_est': search.best_estimator_,\n",
    "                    'best_score': search.best_score_\n",
    "                }\n",
    "                self.prediction = search.best_estimator_.predict(X_user_df)\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        \"Your expected play time as from all users' reviews is: {} hour.\"\\\n",
    "                        .format(self.prediction)\n",
    "                    )\n",
    "        else:\n",
    "            print(\"Game/DILL {} has no review for making any prerdiction.\".format(self.gameID))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08fb350",
   "metadata": {},
   "source": [
    "#### 1.4 Codes for searching games related to the one our user makes a query of; followed by making recommedations based on play time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "924fb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auxiliary functions\n",
    "\n",
    "def get_game_tags(gameID):\n",
    "    game_url = 'https://store.steampowered.com/app/' + str(gameID)\n",
    "    game_page = requests.get(game_url)\n",
    "    game_soup = bs(game_page.content, 'html.parser')\n",
    "    game_tag_html = game_soup.find_all('a', class_=\"app_tag\")\n",
    "    game_tags = []\n",
    "    for tag in game_tag_html:\n",
    "        match = re.search(r'\\s*(\\w*)\\s+',tag.get_text())\n",
    "        if match:\n",
    "            tag = match.group(1)\n",
    "            if tag:\n",
    "                if tag not in game_tags:\n",
    "                    game_tags.append(match.group(1))\n",
    "    return game_tags\n",
    "\n",
    "def get_steam_tags():\n",
    "    tag_url = 'https://store.steampowered.com/tag/browse/#global_492'\n",
    "    tag_page=requests.get(tag_url)\n",
    "    tag_soup = bs(tag_page.content,'html.parser')\n",
    "    tag_html = tag_soup.find_all('div',class_='tag_browse_tag')\n",
    "    tags = []\n",
    "    for tag in tag_html:\n",
    "        match = re.search(\n",
    "            r'<div class=\"tag_browse_tag\" data-tagid=\"(\\d*)\">(\\w*)</div>',\n",
    "            str(tag))\n",
    "        if match:\n",
    "            tags.append([match.group(2),match.group(1)])\n",
    "    return tags\n",
    "\n",
    "def get_tag_scores(steam_tags):\n",
    "    max_score = len(steam_tags)\n",
    "    tag_dict = {}\n",
    "    count = 0\n",
    "    for tag, tag_ID in steam_tags:\n",
    "        tag_dict[tag] = [max_score - count, tag_ID]\n",
    "        count = count + 1\n",
    "    return tag_dict\n",
    "\n",
    "def sort_tags(steam_tags_dict, game_tags):\n",
    "    tags = []\n",
    "    removed_tags = []\n",
    "    for tag in game_tags:\n",
    "        if tag in steam_tags_dict.keys():\n",
    "            tags.append([tag, steam_tags_dict[tag]])\n",
    "        else:\n",
    "            removed_tags.append(tag)\n",
    "    tags.sort(key=lambda x: x[1][0], reverse=True)\n",
    "    if len(removed_tags) > 0:\n",
    "        print(\"The unpopular tag(s), '{}', is/are removed.\"\\\n",
    "              .format(', '.join(removed_tags)))\n",
    "    \n",
    "    return pd.DataFrame(tags, columns = ['tag','(score, id)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c2f153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class recommender(object):\n",
    "    def __init__(self, gameID):\n",
    "        self.game_tags = get_game_tags(gameID)\n",
    "        self.steam_tags = get_tag_scores(get_steam_tags())\n",
    "        self.game_tags_sorted = \\\n",
    "        sort_tags(self.steam_tags, self.game_tags)\n",
    "        \n",
    "    def search_related_games(self,\n",
    "        base_url=\\\n",
    "        'https://store.steampowered.com/search/?sort_by=Released_DESC&tags=',\n",
    "                            verbose=True,\n",
    "                            language='english'):\n",
    "        tag_1_id = self.game_tags_sorted['(score, id)'].iloc[0][1]\n",
    "        tag_2_id = self.game_tags_sorted['(score, id)'].iloc[1][1]\n",
    "        tag_1_tag = self.game_tags_sorted['tag'].iloc[0]\n",
    "        tag_2_tag = self.game_tags_sorted['tag'].iloc[1]\n",
    "        \n",
    "        search_url = \\\n",
    "        base_url + tag_1_id + '%2C' + tag_2_id +'&supportedlang=' + language\n",
    "        \n",
    "        page = requests.get(search_url)\n",
    "        soup = bs(page.content, 'html.parser')\n",
    "        html = soup.find_all('a',class_='search_result_row')\n",
    "        game_search_result = []\n",
    "        for info in html:\n",
    "            match_id = re.search(r'[.\\n]*data-ds-appid=\"(\\d+)',str(info))\n",
    "            match_name = re.search(r'.*https://store.steampowered.com/app/\\d+/(.+)/' ,str(info))\n",
    "            if match_id and match_name:\n",
    "                if match_name.group(1) != '_':\n",
    "                    game_search_result.append([match_name.group(1), match_id.group(1)])\n",
    "        self.related_games = \\\n",
    "        pd.DataFrame(game_search_result,\n",
    "                    columns=['name', 'id'])\n",
    "        if verbose:\n",
    "            if len(game_search_result) > 0:\n",
    "                print(\"Most recent {} and {} games/DILLs (up to 5):\"\\\n",
    "                     .format(tag_1_tag, tag_2_tag))\n",
    "                for name, ID in game_search_result[:5]:\n",
    "                    print(\"Name: {}; ID: {}\"\\\n",
    "                         .format(name, ID))\n",
    "                \n",
    "    def get_related_reviews(self):\n",
    "        ids = self.related_games['id'].values\n",
    "        self.games = {}\n",
    "        for gameID in ids:\n",
    "            game = steam_game(gameID)\n",
    "            game.get_reviews()\n",
    "            if game.ready_for_ML:\n",
    "                game.get_words()\n",
    "                self.games[gameID] = game\n",
    "            else:\n",
    "                print(\"Game/DILL {} has not enough review. SKIPPED.\".format(gameID))\n",
    "            \n",
    "    def get_estimations(self, art_review):\n",
    "        self.predictions = {}\n",
    "        for gameID in self.games.keys():\n",
    "            game = self.games[gameID]\n",
    "            art_review_for_this_game = \\\n",
    "            artificial_reviews(game, \n",
    "                               pre_set_review=art_review.art_review\n",
    "                              )\n",
    "            model = estimator(game)\n",
    "            model.get_play_time(art_review_for_this_game,\n",
    "                               verbose=False)\n",
    "            self.predictions[gameID] = model.prediction\n",
    "        #Merge predictions to search results with names\n",
    "        predictions = []\n",
    "        for gameID in self.related_games['id']:\n",
    "            if gameID in self.predictions.keys():\n",
    "                predictions.append(self.predictions[gameID])\n",
    "            else:\n",
    "                predictions.append(None)\n",
    "        df = self.related_games\n",
    "        df['estimated_playtime'] = predictions\n",
    "            \n",
    "        self.predictions_in_df = \\\n",
    "        df.sort_values(\n",
    "            by=['estimated_playtime'],\n",
    "            ascending=False).reset_index().drop(columns='index')\n",
    "        if df['estimated_playtime'].isnull().values.any():\n",
    "            print(\n",
    "                \"Nan in 'extimated_playtime' is returned for cases with a lack of reviews for making predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f21f8c3",
   "metadata": {},
   "source": [
    "#### 1.5 Codes for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f58bfcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the game you are checking out, please enter its ID on Steam ('q' for exit):1024650\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Skipping previously found appID = 1024650\n",
      "Game records written: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['‘'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter 0 if a property/feature does not make sense to you.\n",
      "Please weight the importance (0-5) of this property/feature: fun 5\n",
      "Please weight the importance (0-5) of this property/feature: type 0\n",
      "Please weight the importance (0-5) of this property/feature: strategy 5\n",
      "Please weight the importance (0-5) of this property/feature: tutorial 5\n",
      "Please weight the importance (0-5) of this property/feature: trading 5\n",
      "Please weight the importance (0-5) of this property/feature: lot 0\n",
      "Please weight the importance (0-5) of this property/feature: bit 0\n",
      "Please weight the importance (0-5) of this property/feature: fun game 5\n",
      "Please weight the importance (0-5) of this property/feature: century 0\n",
      "Please weight the importance (0-5) of this property/feature: simulation 5\n",
      "Please weight the importance (0-5) of this property/feature: garbage 0\n",
      "Please weight the importance (0-5) of this property/feature: ruin 0\n",
      "Please weight the importance (0-5) of this property/feature: favor 0\n",
      "Please weight the importance (0-5) of this property/feature: war 5\n",
      "Please weight the importance (0-5) of this property/feature: game boring 0\n",
      "Please weight the importance (0-5) of this property/feature: half 0\n",
      "Please weight the importance (0-5) of this property/feature: style 0\n",
      "Please weight the importance (0-5) of this property/feature: command 5\n",
      "Please weight the importance (0-5) of this property/feature: cost 5\n",
      "Please weight the importance (0-5) of this property/feature: disappointment 0\n",
      "Your expected play time as from users similar to you is: 754.0 hour.\n",
      "The unpopular tag(s), 'City, Open, Resource', is/are removed.\n",
      "Most recent Action and Adventure games/DILLs (up to 5):\n",
      "Name: Emi__The_Super_Boba; ID: 1766250\n",
      "Name: Hidden_Water; ID: 1778460\n",
      "Name: Miolhr_Starting_Bikes_DLC; ID: 1774530\n",
      "Name: Bigger_Trucks; ID: 1654700\n",
      "Name: Criminal_Russia; ID: 1359430\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1766250\n",
      "[appID = 1766250] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1766250 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1766250 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1766250 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1778460\n",
      "[appID = 1778460] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1778460 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1778460 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1778460 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1774530\n",
      "[appID = 1774530] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1774530 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1774530 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1774530 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1654700\n",
      "[appID = 1654700] expected #reviews = 2\n",
      "[appID = 1654700] num_reviews = 2 (expected: 2)\n",
      "Game records written: 1\n",
      "Game/DILL 1654700 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1654700 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1359430\n",
      "[appID = 1359430] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1359430 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1359430 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1359430 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1755650\n",
      "[appID = 1755650] expected #reviews = 3\n",
      "[appID = 1755650] num_reviews = 3 (expected: 3)\n",
      "Game records written: 1\n",
      "Game/DILL 1755650 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1755650 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1699390\n",
      "[appID = 1699390] expected #reviews = 7\n",
      "[appID = 1699390] num_reviews = 7 (expected: 7)\n",
      "Game records written: 1\n",
      "Game/DILL 1699390 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1699390 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1779290\n",
      "[appID = 1779290] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1779290 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1779290 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1779290 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1749410\n",
      "[appID = 1749410] expected #reviews = 1\n",
      "[appID = 1749410] num_reviews = 1 (expected: 1)\n",
      "Game records written: 1\n",
      "Game/DILL 1749410 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1749410 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1775740\n",
      "[appID = 1775740] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1775740 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1775740 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1775740 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1776350\n",
      "[appID = 1776350] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1776350 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1776350 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1776350 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1742510\n",
      "[appID = 1742510] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1742510 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1742510 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1742510 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1769970\n",
      "[appID = 1769970] expected #reviews = 2\n",
      "[appID = 1769970] num_reviews = 2 (expected: 2)\n",
      "Game records written: 1\n",
      "Game/DILL 1769970 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1769970 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1490890\n",
      "[appID = 1490890] expected #reviews = 1725\n",
      "[appID = 1490890] num_reviews = 1723 (expected: 1725)\n",
      "Game records written: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['‘'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 905220\n",
      "[appID = 905220] expected #reviews = 23\n",
      "[appID = 905220] num_reviews = 23 (expected: 23)\n",
      "Game records written: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['‘'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1774980\n",
      "[appID = 1774980] expected #reviews = 12\n",
      "[appID = 1774980] num_reviews = 12 (expected: 12)\n",
      "Game records written: 1\n",
      "Game/DILL 1774980 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1774980 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1764670\n",
      "[appID = 1764670] expected #reviews = 12\n",
      "[appID = 1764670] num_reviews = 12 (expected: 12)\n",
      "Game records written: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['‘'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1733210\n",
      "[appID = 1733210] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1733210 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1733210 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1733210 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 868800\n",
      "[appID = 868800] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 868800 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 868800 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 868800 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1212180\n",
      "[appID = 1212180] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1212180 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1212180 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1212180 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1663410\n",
      "[appID = 1663410] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1663410 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1663410 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1663410 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1777550\n",
      "[appID = 1777550] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1777550 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1777550 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1777550 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1304400\n",
      "[appID = 1304400] expected #reviews = 7\n",
      "[appID = 1304400] num_reviews = 7 (expected: 7)\n",
      "Game records written: 1\n",
      "Game/DILL 1304400 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1304400 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1740980\n",
      "[appID = 1740980] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1740980 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1740980 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1740980 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1735720\n",
      "[appID = 1735720] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1735720 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1735720 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1735720 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1735710\n",
      "[appID = 1735710] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1735710 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1735710 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1735710 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 705460\n",
      "[appID = 705460] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 705460 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 705460 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 705460 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1724000\n",
      "[appID = 1724000] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1724000 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1724000 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1724000 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1764500\n",
      "[appID = 1764500] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1764500 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1764500 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1764500 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1552610\n",
      "[appID = 1552610] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1552610 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1552610 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1552610 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1757850\n",
      "[appID = 1757850] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1757850 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1757850 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1757850 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1702320\n",
      "[appID = 1702320] expected #reviews = 108\n",
      "[appID = 1702320] num_reviews = 108 (expected: 108)\n",
      "Game records written: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['‘'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1585530\n",
      "[appID = 1585530] expected #reviews = 13\n",
      "[appID = 1585530] num_reviews = 13 (expected: 13)\n",
      "Game records written: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['‘'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1775070\n",
      "[appID = 1775070] expected #reviews = 2\n",
      "[appID = 1775070] num_reviews = 2 (expected: 2)\n",
      "Game records written: 1\n",
      "Game/DILL 1775070 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1775070 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1731520\n",
      "[appID = 1731520] expected #reviews = 95\n",
      "[appID = 1731520] num_reviews = 99 (expected: 95)\n",
      "Game records written: 1\n",
      "Game/DILL 1731520 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1731520 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1674660\n",
      "[appID = 1674660] expected #reviews = 3\n",
      "[appID = 1674660] num_reviews = 3 (expected: 3)\n",
      "Game records written: 1\n",
      "Game/DILL 1674660 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1674660 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1036700\n",
      "[appID = 1036700] expected #reviews = 191\n",
      "[appID = 1036700] num_reviews = 191 (expected: 191)\n",
      "Game records written: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['‘'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1480830\n",
      "[appID = 1480830] expected #reviews = 29\n",
      "[appID = 1480830] num_reviews = 29 (expected: 29)\n",
      "Game records written: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['‘'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1644490\n",
      "[appID = 1644490] expected #reviews = 87\n",
      "[appID = 1644490] num_reviews = 87 (expected: 87)\n",
      "Game records written: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['‘'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 589940\n",
      "[appID = 589940] expected #reviews = 67\n",
      "[appID = 589940] num_reviews = 67 (expected: 67)\n",
      "Game records written: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['‘'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1669560\n",
      "[appID = 1669560] expected #reviews = 3\n",
      "[appID = 1669560] num_reviews = 3 (expected: 3)\n",
      "Game records written: 1\n",
      "Game/DILL 1669560 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1669560 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1550760\n",
      "[appID = 1550760] expected #reviews = 18\n",
      "[appID = 1550760] num_reviews = 18 (expected: 18)\n",
      "Game records written: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['‘'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1778800\n",
      "[appID = 1778800] expected #reviews = 128\n",
      "[appID = 1778800] num_reviews = 128 (expected: 128)\n",
      "Game records written: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['‘'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 780310\n",
      "[appID = 780310] expected #reviews = 1971\n",
      "[appID = 780310] num_reviews = 1753 (expected: 1971)\n",
      "Game records written: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['‘'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1456880\n",
      "[appID = 1456880] expected #reviews = 93\n",
      "[appID = 1456880] num_reviews = 93 (expected: 93)\n",
      "Game records written: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['‘'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1632140\n",
      "[appID = 1632140] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1632140 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1632140 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1632140 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1444920\n",
      "[appID = 1444920] expected #reviews = 93\n",
      "[appID = 1444920] num_reviews = 93 (expected: 93)\n",
      "Game records written: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/delcck/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['‘'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1652000\n",
      "[appID = 1652000] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1652000 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1652000 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1652000 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1575900\n",
      "[appID = 1575900] expected #reviews = 1\n",
      "[appID = 1575900] num_reviews = 1 (expected: 1)\n",
      "Game records written: 1\n",
      "Game/DILL 1575900 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1575900 has not enough review. SKIPPED.\n",
      "Loading idprocessed_on_20211017.txt\n",
      "Downloading reviews for appID = 1763990\n",
      "[appID = 1763990] num_reviews = 0 (expected: -1)\n",
      "Game records written: 1\n",
      "Game/DILL 1763990 has no review yet. An empty data set will be returned.\n",
      "Game/DILL 1763990 has less than 5 reviews. No further ML-based analyses will be made.\n",
      "Game/DILL 1763990 has not enough review. SKIPPED.\n",
      "Nan in 'extimated_playtime' is returned for cases with a lack of reviews for making predictions.\n",
      "Games/DILL recommendations based on your input related to game 1024650.\n",
      "+-------------------------------------------------------------------------+----------------------+\n",
      "| name                                                                    |   estimated_playtime |\n",
      "|-------------------------------------------------------------------------+----------------------|\n",
      "| Blast_Brigade_vs_the_Evil_Legion_of_Dr_Cread                            |               1745.6 |\n",
      "| The_Riftbreaker                                                         |               1037.2 |\n",
      "| Demon_Slayer_Kimetsu_no_Yaiba_The_Hinokami_Chronicles                   |                861.4 |\n",
      "| My_Beautiful_Paper_Smile                                                |                508   |\n",
      "| Bloody_Everybody                                                        |                379   |\n",
      "| ElecHead                                                                |                356.4 |\n",
      "| PIGGY_Hunt                                                              |                317.4 |\n",
      "| Occult                                                                  |                300.4 |\n",
      "| Doctor_Who_The_Edge_of_Reality                                          |                297   |\n",
      "| Evil_Tonight                                                            |                258   |\n",
      "| Eye_of_the_Temple                                                       |                108.4 |\n",
      "| GunWorld_VR                                                             |                108   |\n",
      "| Grim_Earth                                                              |                 98.2 |\n",
      "| NAEU_Black_Desert__FREE_Gift_Pack                                       |                  0   |\n",
      "| Emi__The_Super_Boba                                                     |                nan   |\n",
      "| Hidden_Water                                                            |                nan   |\n",
      "| Miolhr_Starting_Bikes_DLC                                               |                nan   |\n",
      "| Bigger_Trucks                                                           |                nan   |\n",
      "| Criminal_Russia                                                         |                nan   |\n",
      "| CAPS__Cyber_Animal_Planet_Survival                                      |                nan   |\n",
      "| Roxy_Raccoon                                                            |                nan   |\n",
      "| CHRONICLES_OF_2_HEROES_AMATERASUS_WRATH                                 |                nan   |\n",
      "| DARK_MAGIC_2                                                            |                nan   |\n",
      "| KSTG                                                                    |                nan   |\n",
      "| Bear_Adventures                                                         |                nan   |\n",
      "| Wreckdigger                                                             |                nan   |\n",
      "| Demon_Slayer_Kimetsu_no_Yaiba_The_Hinokami_Chronicles_Core_Addon_Bundle |                nan   |\n",
      "| Cursed__Dungeon                                                         |                nan   |\n",
      "| SafeZone_Founder_DLC                                                    |                nan   |\n",
      "| Force_of_Nature_Soundtrack                                              |                nan   |\n",
      "| Ravesta_Racing                                                          |                nan   |\n",
      "| Happenlance                                                             |                nan   |\n",
      "| Fuyu_no_Tsuma                                                           |                nan   |\n",
      "| The_End_of_Dyeus                                                        |                nan   |\n",
      "| ___Run_For_Life                                                         |                nan   |\n",
      "| _Secret_Mission                                                         |                nan   |\n",
      "| __Fight_Aong                                                            |                nan   |\n",
      "| Bounty_Below__Golden_cursor                                             |                nan   |\n",
      "| TimeLock_VR2                                                            |                nan   |\n",
      "| Rogue_Planet_1_Golden_Hour                                              |                nan   |\n",
      "| Voidwalkers__Astoras_Darkness__Character_Editor                         |                nan   |\n",
      "| RebirthLand_of_Zombies                                                  |                nan   |\n",
      "| Doctor_Who_The_Edge_of_Reality__Deluxe_Edition                          |                nan   |\n",
      "| Ark_Mobius_Censored_Edition                                             |                nan   |\n",
      "| Cards_of_the_Dead__Prologue                                             |                nan   |\n",
      "| Into_the_Loop                                                           |                nan   |\n",
      "| Girl_Agent                                                              |                nan   |\n",
      "| Peekazoo                                                                |                nan   |\n",
      "| Old_Stories_Fireheart                                                   |                nan   |\n",
      "| Dice_vs_Dice                                                            |                nan   |\n",
      "+-------------------------------------------------------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #Get game ID\n",
    "    while True:\n",
    "        try:\n",
    "            inp = \\\n",
    "            input(\n",
    "                \"For the game you are checking out, please enter its ID on Steam ('q' for exit):\"\n",
    "                )\n",
    "            if inp == 'q':\n",
    "                break\n",
    "            game_id = int(inp)\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Game ID should be an integer.\")\n",
    "    if inp != 'q':\n",
    "        #Get reviews for analyses\n",
    "        game = steam_game(game_id)\n",
    "        game.get_reviews()\n",
    "        game.get_words()\n",
    "        if game.ready_for_ML:\n",
    "            print(\"Please enter 0 if a property/feature does not make sense to you.\")\n",
    "            weight_pos = get_feature_weights(game.word_pos)\n",
    "            weight_neg = get_feature_weights(game.word_neg)\n",
    "            art_review = artificial_reviews(\n",
    "                game,\n",
    "                weight_pos=weight_pos,\n",
    "                weight_neg=weight_neg\n",
    "            )\n",
    "            user = estimator(game)\n",
    "            user.get_play_time(art_review)\n",
    "            game_recommend = recommender(game.gameID)\n",
    "            game_recommend.search_related_games()\n",
    "            game_recommend.get_related_reviews()\n",
    "            game_recommend.get_estimations(art_review)\n",
    "            print(\"Games/DILL recommendations based on your input related to game {}.\"\\\n",
    "                 .format(game.gameID))\n",
    "            print(tabulate(\n",
    "                game_recommend.predictions_in_df[['name','estimated_playtime']], \n",
    "                headers='keys', tablefmt='psql',\n",
    "                showindex=\"never\"))\n",
    "            \n",
    "        else:\n",
    "            print(\"Game/DILL {} does not have adequate reviews for analyses.\")\n",
    "    else:\n",
    "        print(\"Exit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c264bb89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
